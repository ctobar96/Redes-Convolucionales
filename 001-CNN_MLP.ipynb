{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://i.ibb.co/v3CvVz9/udd-short.png\" width=\"150\"/>\n",
    "    <br>\n",
    "    <strong>Universidad del Desarrollo</strong><br>\n",
    "    <em>Magíster en Data Science</em><br>\n",
    "    <em>Profesor: Tomás Fontecilla </em><br>\n",
    "\n",
    "</div>\n",
    "\n",
    "## <center> **TAREA: Redes Convolucionales** </center>\n",
    "\n",
    "*02 de Diciembre de 2024*\n",
    "\n",
    "**Nombre Estudiante**: Cristian Tobar Morales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Introducción**\n",
    "\n",
    "En esta tarea, aplicaremos redes neuronales convolucionales (CNN) utilizando la base de datos \"Chihuahuas vs Muffin\" de Kaggle. Además, compararemos los resultados obtenidos con un modelo de perceptrón multicapa (MLP) para determinar cuál de los dos modelos ofrece una mejor precisión en la clasificación de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Objetivo**\n",
    "\n",
    "El objetivo es analizar y evaluar el rendimiento de ambos enfoques en términos de precisión y eficacia, proporcionando una visión clara sobre sus fortalezas y debilidades en la tarea de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Metodología**\n",
    "\n",
    "- Lectura y pre-procesamiento del Conjunto de Datos.\n",
    "- Visualizando Imágenes\n",
    "-\tPerceptrón Multicapa para Clasificación de Imágenes\n",
    "-\tRedes Neuronales Convolucionales\n",
    "-\tConclusión \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Librerías requeridas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import zipfile\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from keras.datasets import mnist # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense \n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lectura y pre-procesamiento del Conjunto de Datos**\n",
    "\n",
    "La lectura de los sets de entrenamiento y validacion.\n",
    "\n",
    "Antes de entrenar el modelo debemos:\n",
    "- Normalizar los valores de los píxiles de los datos en el mismo rango (0,1).\n",
    "- División del conjunto de datos (Prueba y entrenamiento). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo ZIP \n",
    "zip_path = '../Redes-Convolucionales/data/datos.zip' \n",
    "extract_path = '../Redes-Convolucionales/data'\n",
    "# Abre el archivo Zip\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref: \n",
    "    zip_ref.extractall(extract_path)    \n",
    "    \n",
    "# Rutas de los datos\n",
    "train_dir = '../Redes-Convolucionales/data/train'\n",
    "test_dir = '../Redes-Convolucionales/data/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el conjunto de datos de entrenamiento y prueba. \n",
    "\n",
    "- **IMAGEN_SIZE**: Se implementa un tamaño de 128x128 píxeles, que funciona bien con muchas arquitecturas de modelos.\n",
    "- **BATCH_SIZE**: Define el número de muestras que se procesan antes de que el modelo actualice sus pesos, se utilizará un número de 64.\n",
    "\n",
    "- **ImageDataGenerator**: Para escalar los píxeles de las imágenes y aplicar aumentos como volteos verticales y horizontales. Esto ayudará a mejorar la generalización de tu modelo al introducir variaciones en las imágenes de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BATCH_SIZE = 64 \n",
    "IMAGEN_SIZE = (128, 128) \n",
    "\n",
    "\n",
    "def verify_images(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    img.verify()  # Verificar que el archivo es una imagen válida\n",
    "            except (UnidentifiedImageError, IOError):\n",
    "                os.remove(file_path)  # Eliminar el archivo no válido\n",
    "\n",
    "# Verificar imágenes en los directorios de entrenamiento y prueba\n",
    "verify_images(train_dir)\n",
    "verify_images(test_dir)\n",
    "\n",
    "\n",
    "# Crear un generador de datos\n",
    "data_generator = ImageDataGenerator(rescale=1./255, # Normalizar las imágenes\n",
    "                                    rotation_range=20,  # Rotar las imágenes aleatoriamente dentro de un rango de 20 grados\n",
    "                                    zoom_range=0.2,  # Aplicar zoom aleatorio a las imágenes\n",
    "                                    fill_mode='nearest',  # Utilizar 'nearest' para completar píxeles faltantes tras transformaciones\n",
    "                                    channel_shift_range=0.1,  # Desplazamiento aleatorio de los canales de color\n",
    "                                    vertical_flip=True, \n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "# Cargar el conjunto de datos de entrenamiento\n",
    "train_dataset = data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGEN_SIZE,  \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary' #Clasificación binaria\n",
    ")\n",
    "\n",
    "# Cargar el conjunto de datos de prueba\n",
    "test_dataset = data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMAGEN_SIZE,  \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary' \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
